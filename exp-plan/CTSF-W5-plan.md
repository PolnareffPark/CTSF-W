# W5. **게이트 고정(동적→정적의 중간) 시험** 〔**권장 보완**〕

### 목적

- **동적 적응성 자체의 순효과**를 직접 확인.
    

### 근거(직접 인용)

- Dynamic Filter: “**produces filters conditioned on an input**.”(입력 조건) ([NeurIPS Papers](https://papers.neurips.cc/paper/6578-dynamic-filter-networks.pdf?utm_source=chatgpt.com "Dynamic Filter Networks"))
    
- HyperNetworks: “**generate weights for another neural network**.”(가중 생성) ([deepsense.ai](https://deepsense.ai/wp-content/uploads/2023/03/1609.09106.pdf?utm_source=chatgpt.com "HyperNetworks"))
    

### 모델 조작

- 학습 종료 시점의 **Cross 게이트 통계(평균/분산)**를 추출 → **평균값으로 고정**하여 재평가(추가 학습 없이 forward만).
    
- HP2 동일.
    

### 평가·판정

- **고정 시** TOD 민감도·피크 반응 **유의 하락** + ΔRMSE 악화 ⇒ **샘플별 동적 적응**의 실효성 입증.

---

W5 실험 – 게이트 고정 시험 (동적→정적 중간 형태)
[배경 및 필요성]: W2에서 동적 vs 정적 전체 구조를 비교했다면, W5는 동적 구조 내에서의 미세 분석입니다. 동적 하이퍼네트워크가 성능 향상에 얼마나 기여하는지 정량적 순효과를 확인하기 위해, 학습된 동적 게이트를 고정시켜 보는 실험입니다. 이는 일종의 사후 해석(post-hoc) 실험으로, “동적 적응성 자체가 없다면 성능이 얼마나 떨어지는가?”를 봄으로써 dynamic 구문의 순이익을 가늠할 수 있습니다.
[실험 목적]: 학습을 끝낸 CTSF 모델에서 교차 게이트(gating)의 동적 변동성을 제거한 채로 성능을 측정합니다. 즉, 동적→정적의 중간 케이스를 실험하여, 동적 적응성의 중요도를 확인합니다.
[이론적 근거]: 근거는 W2와 동일한 맥락으로, Dynamic Filter, HyperNetwork의 유용성을 들 수 있습니다[20][21]. 차이는, 여기서는 학습된 모델 내부에서 게이트 변수를 고정해보는 것이므로, 가중치를 다시 학습하진 않지만 inference 단계에서 동적 기능만 OFF하는 특수 실험입니다. 이를 통해 “학습된 dynamic이 얼마나 역할을 했는가”를 직접 확인할 수 있습니다.
[모델 조작]: - 완전 학습된 CTSF 모델 (both 설정)을 준비합니다. - 각 교차 계층의 게이트 파라미터 출력 분포를 분석하여, 평균값을 계산합니다. (예: CrossHyperConv 모듈 내부에서 time-step마다 생성되는 α, β 등의 평균) - 모델을 수정하지 않고, 추론 시에 한해 각 시간 스텝의 게이트를 그 평균값으로 고정하여 forward를 진행합니다. - 즉, dynamic한 변화 대신 항상 평균 게이트만 적용된 상태로 전체 테스트 세트를 통과시켜 성능을 재평가합니다. (학습은 하지 않고 평가만 함) - 이 작업은 구현 시 간단히, 코드 상에서 gating 텐서를 불러온 뒤 tensor.fill_(mean)으로 채우거나 하는 식으로 처리합니다.
[평가 및 판정]: - TOD 민감도와 피크 반응 지표를 고정 전후로 비교합니다. 만약 게이트 고정으로 성능이 떨어진다면 동적 적응이 유효했다는 의미입니다: - RMSE 증가: 게이트 고정 모델의 RMSE가 원래 모델보다 상승 (악화)할 것입니다. - TOD 민감도 감소: 원래 dynamic 모델에서 높게 나타났던 시간대별 필터 반응성이, 게이트 고정으로 줄어듭니다. - 피크 검출 감소: 피크 반응 지표 (event gain 등)도 저하. - 이 변화들이 유의미해야 합니다 (예: RMSE 상승 폭의 95% CI가 0을 상회). - 판정: 위 변화가 뚜렷하면 “동적 게이트의 샘플별 변화가 성능에 기여했다”라고 결론짓습니다. 만약 변화가 미미하다면 dynamic 효과가 생각만큼 크지 않았을 수도 있지만, 일반적으로는 어느 정도 차이가 날 것으로 예상합니다.
[기대 해석]: - 게이트를 고정한다는 것은, 일종의 CTSF를 static 모드로 강제하는 효과가 있습니다 (하지만 가중치 자체는 dynamic 학습된 값이라 W2의 static 모델과는 다름). - 이때 성능이 눈에 띄게 나빠진다면, 이는 실제 각기 다른 상황에서 게이트가 제 역할을 했음을 의미합니다. 즉, 동적 적응성의 순효과를 수치로 보여주는 셈입니다. - 특히, 시간별 패턴이 다양한 데이터일수록 게이트 고정 시 타격이 클 것입니다. 예를 들어 Weather나 ECL 같은 데이터에도 적용해볼 수 있으며, 거기서도 확인된다면 general하게 dynamic의 가치가 증명됩니다. - 이 실험은 독립 변인 통제가 어렵지만 (학습 관여 없이 inference만 바꾸는 것이라), “dynamic이 없다면 이 정도 나빠진다”는 메시지를 주기에 유용합니다.
[보고 형식]: - 표: 원래 모델 vs 게이트평균 고정 모델의 RMSE, MAE, TOD, 피크 지표를 비교. - 도식: 간단한 막대그래프 등으로 RMSE 상승폭을 보여주거나, 게이트 분포를 그림으로 삽입하여 게이트가 얼마나 다양하게 쓰였는지 시각화합니다.
