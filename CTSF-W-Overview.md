CTSF-W 실험 개요 (Overview)

CTSF 연구 개요 (모델 목적 및 구성)

CTSF (Custom Time Series Forecast) 모델은 다변량 시계열 예측 문제에서 경량이면서도 적응적인 예측을 목표로 개발되었습니다. 이 모델은 1D CNN과 GRU의 병렬 하이브리드 구조로 이루어져 있으며, 두 경로 간에 교차 연결(Cross Connection)을 도입한 것이 가장 큰 특징입니다. 입력 시계열은 우선 채널 혼합(Patch Embedding)층을 통해 모든 변수들의 공통 변화 신호를 추출한 후, 일정 길이의 Patch로 분할되어 ① CNN 경로, ② GRU 경로, ③ Residual 경로에 동시에 투입됩니다[1][2]. 각 계층(block)마다 동적 깊이별 컨볼루션 (Dynamic Depth-Wise Convolution)을 수행하는데, 이때 상대 경로의 상태를 조건으로 삼아 채널별 필터를 재구성합니다. 이를 통해 시점별 문맥에 맞게 가중치가 조정되어 상태 의존적 업데이트가 이루어지며, 매 계층에서 교차 경로 신호로 상호 보정되는 교차-학습(cross-learning)이 일어납니다[3][4]. 이러한 구성으로 (i) 채널별 독립 처리의 한계를 보완하고, (ii) 현재 상태에 따른 적응형 필터링으로 급격한 변동을 흡수하며, (iii) 트랜스포머 대비 훨씬 경량 구조로 효율성을 확보하고, (iv) 기존 CNN-GRU 결합 모델들의 후기 결합(late-fusion) 문제(학습 단계에서 경로 간 상호작용 부족)를 해소할 수 있다는 장점이 있습니다[5][4].

요약하면, CTSF 모델은 GRU 경로의 장기 의존성 추출 능력과 CNN 경로의 국소 패턴 포착 능력을 교차 연결을 통해 통합함으로써, 분포 변동이나 복잡한 계절성을 지닌 시계열에 대해 강건한 예측 성능을 발휘하도록 설계되었습니다. GRU 경로는 저주파 골격 정보와 상태 요약을 담당하고, CNN 경로는 피크·기울기·변곡점 등의 형태학적 단서를 포착합니다. Cross-Modal Attention으로 구현된 교차 연결 메커니즘은 GRU가 포착한 저주파 추세 위에서 CNN이 포착한 고주파 요동 중 맥락적으로 의미 있는 부분만 강조하도록 만들어 주며, 두 경로의 특성 융합을 통해 최종 예측 성능을 높입니다[6]. 또한 Reversible Instance Normalization (RevIN) 등을 활용하여 데이터의 비정상성(분포 변동)에 대응하고, Depth-wise Convolution과 초매개생성(hypernetwork) 기법으로 계층별 필터를 입력 의존적으로 생성함으로써, 시간대별 특성과 극단값에 대한 적응성을 높이는 구성을 가지고 있습니다.

모델 구조를 요약하면 다음과 같습니다:

입력 정규화 및 패치 임베딩: RevIN으로 각 배치의 분포를 정규화한 뒤, 1D Conv 층 하나로 모든 입력 채널을 선형 결합하여 patch 토큰을 생성합니다[7]. 이 채널 혼합 단계는 여러 변수의 공통 변동 신호를 추출하여 채널 간 상호작용을 초기 단계부터 반영합니다. 그 결과 PatchTST류의 채널 독립 접근과 달리, 입력 단계에서부터 변수 간 공유 표현을 만듭니다.

병렬 CNN-GRU 경로: Patch 단위로 시퀀스를 나누어 1D-CNN 블록과 GRU 블록에 병렬 투입합니다. CNN 경로는 합성곱 필터로 지역 패턴(예: 짧은 주기의 변화, 피크)을 포착하고, GRU 경로는 순환신경망으로 장기 추세와 시퀀스 의존성을 학습합니다[1]. 각 경로는 여러 계층으로 구성되며, 계층 깊어질수록 추상화 수준이 높아집니다.

교차 연결 및 동적 필터: 각 계층마다 CNN 출력과 GRU 출력을 교차로 결합하는 모듈이 존재합니다. 이는 Cross-Stitch Unit과 유사하게 두 경로의 활성화를 선형 결합하여 공유/전용 표현을 혼합하고[8], 더 나아가 HyperNetwork를 통해 GRU의 상태에 의존하여 CNN의 Depth-Wise Conv 필터를 생성하거나 (또는 그 반대) 동적으로 가중합니다[9]. 이 양방향 교차 업데이트로 인해 CNN과 GRU 경로는 훈련 전체 과정에 걸쳐 상호 보정되고, 계층별로 적절히 정보가 교환됩니다. 결과적으로, 단순히 마지막에 합치는 모델 대비 깊이에 따른 단계별 보정 효과를 얻어내어 표현력을 향상시킵니다.

출력 및 역정규화: 최종 계층 출력에서는 CNN과 GRU 경로의 예측을 다시 결합하여 (예: Concatenation 후 Linear 등) 최종 예측값을 산출하고, RevIN의 역변환을 통해 원래 스케일로 복원하여 결과를 얻습니다.

CTSF 모델의 설계 철학은 “각 계층마다 교차로 신호를 주고받으며 학습할 때 최적의 성능을 낸다”는 것입니다. 이는 다중 경로 네트워크에서 층별 공유 vs 전용 표현의 균형을 맞추는 원리와, 문맥에 따라 가중치가 변하는 동적 업데이트의 이점을 모두 활용하려는 의도입니다. 다음 섹션에서는 지금까지의 연구 경과와 발견된 사실들을 요약합니다.

연구 경과 요약 (현재까지의 연구 진행 상황)

CTSF 모델 연구는 2023년 말부터 시작되어, 모델 구조 확립과 파일럿 실험을 거쳐 지속적인 개선과 분석이 이루어졌습니다. 지금까지의 주요 연구 경과를 요약하면 다음과 같습니다:

기본 모델 개발 및 검증: 초기 버전 CTSF-V1 모델이 구현되어 ETT, Weather 등 대표 시계열 데이터셋을 대상으로 예비 실험이 수행되었습니다. 이때 채널 혼합 + Patch 분할 + CNN-GRU 병렬 + 교차 연결이라는 기본 구조의 유효성을 확인하였고, 기존 최신 예측 모델들과 비교해서도 경쟁력 있는 성능을 보임을 확인했습니다. 특히 ETTm2, ETTh2 데이터셋에서 다른 모델 대비 RMSE, MAE가 크게 개선되어, 해당 데이터의 특성과 모델 구조의 매칭 효과가 있음이 시사되었습니다.

성능 분포 및 데이터 특성 분석: 왜 ETTh2, ETTm2에서 성능 이득이 큰지 해석하기 위해 데이터 수준 분석(Data-Level Analysis)을 수행하였습니다[10]. 피어슨 상관계수, 자기상관함수(ACF), 채널 상관행렬 엔트로피, 신호대잡음비(SNR), 스파이크 빈도 등의 지표를 계산한 결과, ETTh2와 ETTm2 데이터는 일별/주별 계절 주기가 뚜렷하고 SNR이 높으며, 채널 간 중복정보가 적절히 혼재되어 있어 본 모델의 설계 의도에 부합함을 보였습니다[11][12]. 반면 ETTh1, ETTm1 등의 데이터는 주기성이 상대적으로 약해 본 모델의 이득이 작게 나타남을 확인하였습니다 (예: Shuffle/Sdiff로 계절 패턴을 교란한 실험에서 ETTh2/m2는 성능 큰 폭 하락 → 계절 정합이 이득원[13]).

핵심 구성요소에 대한 Ablation 실험: 모델의 각 구성 (교차 연결, Depth-wise Conv 동적 생성 등)의 기여도를 정량화하기 위해 일련의 가설 기반 실험(H1~H4 등)을 진행하였습니다[14][15].

가설 H1: 강한 계절성을 가진 데이터에서 성능 이득이 크다 – 계절성 교란 실험으로 검증 (계절 패턴을 무력화하면 성능 격차 축소)[13].

가설 H2: 동일 시각에 등장하는 다양한 변수 신호의 동시 활용이 이득에 기여한다 – cross-stitch 유닛의 이득 및 shuffle 실험으로 검증 (동일 timestep의 멀티버리엇 신호 결합이 중요)[16].

가설 H3: 동적 Depth-wise Conv의 기여 – 동적 필터 생성에 사용되는 조건 벡터를 고정/약화/제거(정적)한 실험으로 검증. 그 결과 동적 요소를 제거하면 성능 급락하여 동적 필터링이 장기 Horizon에서 특히 중요함을 확인[17].

가설 H4: 교차 연결의 계층별 효과 – 얕은 층/중간 층/깊은 층 교차만 남기는 실험으로, 데이터에 따라 어느 층의 교차가 가장 기여도가 큰지 관찰. ETTh2의 경우 초반 층 교차가, ETTm2의 경우 후반 층 교차가 더 중요해 보이는 경향을 확인하였고, 이는 각 데이터의 주기 패턴과 관련지어 해석되었습니다.

설계 철학 재확인: 위 실험들을 통해 CTSF 모델의 주요 설계에 대한 정당성이 상당 부분 입증되었습니다. 층마다의 교차 결합이 단 한 번의 결합보다 우수했고, 동적 필터 생성이 정적 결합보다 나은 성능을 보였으며, 채널 혼합+교차 설계 자체의 효과가 모델 파라미터 수나 연산량의 증가 때문이 아님을 FLOPs/파라미터 동등 실험으로 확인하였습니다. 이러한 결과는 Cross-Stitch Networks 등 선행 연구의 멀티-패스 학습 원리와 부합하며, CTSF만의 경량 구조에서도 이러한 이점을 구현했음을 보여줍니다.

연구 발표 및 피드백: 현재까지 CTSF 012 등 내부 발표자료를 통해 중간결과를 공유했고, CTSF Summary 002에서는 질의응답 형태로 주요 개념을 정리한 바 있습니다. 연구 면담을 통해 받은 피드백으로는 “설계 목적과 데이터 특성 간 관계를 명확히 하라”, “교차로 인한 이득을 직접 입증할 실험이 필요하다” 등이 있었고, 이를 반영하여 후속 실험 계획(W 실험군)을 수립하게 되었습니다.

이제, 앞으로 수행할 CTSF-W 실험군 (W1~W5)의 구체적인 목적과 계획에 대해 설명합니다. 이 실험군은 기존 CTSF 모델에서 제안한 교차 연결 구조의 정당성, 설계 철학, 데이터 적합성 등을 보다 엄밀히 검증하기 위한 것으로, 각각의 실험이 다루는 가설과 변경 요소를 최소화하여 모델 구조의 원래 의도를 하나씩 입증하고자 합니다.

W1~W5 실험 개요 및 배경

CTSF-W 실험군은 총 5개 실험 (W1–W5)으로 구성되며, 각 실험은 앞서 요약된 연구 결과에서 도출된 핵심 가설을 검증하도록 설계되었습니다. W 실험에서는 모델 구조 변경을 절대 하지 않고, 오직 실험 목적에 해당하는 부분만 최소한으로 수정하여 영향을 관찰합니다 (모든 W 실험 공통 원칙). 아래에 각 실험의 필요성, 목적, 이론적 배경, 구체적인 모델 조작 방법, 사용될 평가 지표 및 통계 분석, 예상되는 결과 해석을 순서대로 기술합니다.

※ 중요: W 실험에서는 모델 구조를 절대로 변경하지 않습니다. 기본 CTSF 모델과 동일한 구조를 유지하되, 실험 목적상 필요한 일부 모듈만 on/off하거나 조건을 변경하는 식으로 최소한의 조작만 가합니다. 이를 통해 설계 철학의 효과만을 분리하여 검증합니다.

W1 실험 – 층별 교차 vs. 최종 결합 (Late Fusion)

[배경 및 필요성]: CTSF의 핵심 철학 중 하나는 “계층마다 교차로 신호를 섞는 것”입니다. 만약 교차 연결을 각 층에서 하지 않고 맨 마지막 한 번만 두 경로 출력을 합친다면 성능이 어떻게 달라질까요? W1 실험은 “왜 매 층 교차해야 하는가?”에 답하기 위한 것으로, 층별 교차 보정이라는 설계 철학의 핵심 정당성을 직접 검증합니다. 이는 Cross-Stitch Networks 등의 선행 연구에서 층별 공유/전용 표현 균형이 성능 향상에 중요하다고 보고한 것과 맥락을 같이 합니다.

[실험 목적]: Per-layer 교차 연결된 원래 모델과, Last-layer에서 한 번만 결합하는 대조 모델을 비교하여, 계층별 교차의 효과를 정량적으로 확인합니다. 만약 층별 교차가 없다면 성능이 떨어지는지를 입증함으로써, CTSF 구조의 우월성을 보이고자 합니다.

[이론적 근거]: 선행 문헌에서 층별 결합의 중요성을 찾을 수 있습니다: - Cross-Stitch Network (멀티태스크 학습)에서는 “At each layer we learn a linear combination of the activation maps from both the tasks.”[18]라고 하여, 매 층에서 두 경로의 활성화를 섞어 공유 표현과 전용 표현 간 균형을 맞추는 것이 성능 향상의 비결임을 보여줍니다. → 실제로 해당 논문에서 제안한 층별 결합 모델은 baseline 대비 성능 향상을 달성하였으며, 이는 깊이 방향으로 계층별 보정이 일어났기 때문으로 해석됩니다[8]. - Feature-Dependent Cross-Connections (다중 경로 CNN) 연구에서는 “inserting feature‑dependent cross‑connections between parallel sets of feature maps … coefficients are computed from the input features.”[19]라고 하여, 연속된 계층 사이에 특성 의존적 교차연결을 삽입하면 정확도 향상을 보였다고 보고합니다. → 병렬 경로를 입력 상황에 따라 동적으로 연결해 줌으로써, 단순 병렬보다 일관된 성능 개선이 나타난 사례입니다 (동 논문 ICPR 2020).

[모델 조작]: - 원안 (Per-layer Cross): 기본 CTSF 모델 그대로, 모든 블록에 양방향 교차 연결(CrossHyperConv 블록 활성) 사용. - 대조군 (Last-layer Fusion): 각 블록의 교차 연결을 모두 비활성화하고, 맨 마지막에만 두 경로 출력을 결합합니다. 결합 방법은 concat → 1×1 conv 또는 FiLM 등으로 구현하되, 모델 파라미터 수와 FLOPs를 원안과 ±3% 이내로 맞춰 용량 차이를 통제합니다. (해당 용량 매칭은 실험 B1에서 다시 엄밀히 확인) - 그 외 설정: 동일한 하이퍼파라미터 세트 (HP2 세팅)로 학습합니다. 시드, 학습 epoch 등도 동일하게 유지하고, 교차 연결 on/off 이외의 구조 변화는 일절 없음을 강조합니다.

[평가 지표 및 통계]: - 주요 성능 지표: 각 설정에 대해 RMSE (실제값 스케일), MSE_std (표준화 스케일), MAE 등을 산출합니다. 특히 RMSE(real)로 성능 비교. - 직접 근거 지표: 교차 연결이 미치는 영향을 세부적으로 보기 위해 TOD(time-of-day) 민감도 지표 2종과 피크 반응 관련 지표 3종을 추가로 측정합니다. 예컨대 GRU→CNN 경로의 필터 변화 vs 시간대 상관성 (TOD 민감도), CNN→GRU 경로의 피크 이벤트 검출 정도, 최대 상관 및 시차 등을 계산하여, 두 설정 간 컨텍스트 정렬 능력 차이를 분석합니다. - 통계 분석: 동일 데이터셋·Horizon별로 대응 표본 t-검정을 수행하여, Per-layer 모델이 Last-layer 모델 대비 우월한지 여부를 유의수준(p-value)으로 검증합니다. 또한 모든 지표에서 우월한 경향이 있는지 포괄 검정합니다.

판정 기준: 기대되는 결과는 Per-layer Cross 모델이 Last-layer Fusion 모델보다 모든 주요 지표에서 더 나은 성능을 보이는 것입니다. 특히 ETTm2/ETTh2와 같이 본 모델 이득이 컸던 데이터셋에서는 성능 격차가 유의하게 크게 나타날 것으로 예상합니다.

[기대되는 관찰 및 해석]: - Last-layer 한 번의 융합만으로는 두 경로의 학습이 부분적으로만 상호작용하므로, 깊이에 따른 단계별 보정이 이루어지지 못합니다. 그 결과 Residual 경로로만 두 신호가 최종 합쳐져 표현력이 제한되고, 오차 누적을 효과적으로 완화하지 못해 성능이 떨어질 것입니다. - 반면 Per-layer 교차 모델은 매 층마다 CNN과 GRU가 서로의 상태를 참조하여 오류를 교정하고 표현 공간을 공유하므로, 수용 영역(receptive field)이 확장되고 문맥 vs 모양 단서가 적절히 정렬되어 최종 성능이 향상됩니다. 이를 성능 격차로 확인할 수 있을 것입니다. - 특히, 교차 연결이 없는 모델은 특정 시간대(예: 야간 vs 주간)별로 성능 편차가 커지거나, 피크 응답의 지연이 발생하는 등 한계가 드러날 것으로 예상합니다. 이러한 패턴 차이를 TOD 민감도와 피크 반응 지표에서 확인하면, 층별 교차의 역할을 뒷받침하는 직접적 증거가 될 것입니다.

[결과 보고 형식]: - 표(Table): 각 데이터셋 × Horizon 조합마다, Per-layer 대비 Last-layer 설정의 ΔRMSE (차이), TOD 민감도 차이, 피크 반응 및 시차 차이를 정리합니다 (평균±신뢰구간, 및 대응 t-검정 p-value 표기). - 그림(Figure): 레이더 차트 또는 포리스트 플롯을 그려서, 데이터셋별로 두 설정 간 효과 크기를 시각화합니다. 예컨대 ETTm2의 경우 거의 모든 지표에서 Per-layer가 우세함을 한 눈에 보여줄 계획입니다.

W2 실험 – 동적 교차 vs. 정적 교차

[배경 및 필요성]: W1이 “어디서 교차하느냐”를 다뤘다면, W2는 “어떻게 교차하느냐”에 대한 실험입니다. CTSF의 교차 연결은 GRU의 상태 (문맥)에 따라 CNN 필터/출력 가중치가 매 스텝 달라지는 동적(hypernet) 결합인데, 이러한 동적 특성이 없다면 어떻게 될까요? 본 실험은 “왜 교차 연결이 동적으로 이루어져야 하는가?”를 검증합니다. 이는 입력-조건부 가중치 생성이라는 일반 원리가 시계열 모델에서 성능 향상에 기여하는지 확인하는 작업입니다.

[실험 목적]: Dynamic Cross (문맥 의존)와 Static Cross (고정 가중)의 예측 성능을 비교합니다. 즉, 현재 시점의 GRU hidden state를 반영하여 CNN 쪽 가중치를 생성하는 현행 방식을, 동일 용량의 고정 결합 방식으로 대체하여 성능 차이를 관찰합니다. 이를 통해 문맥에 따른 가중 동조의 효과를 규명합니다.

[이론적 근거]: 맥락 적응의 장점은 여러 연구에서 제시되어 왔습니다: - Dynamic Filter Networks에서는 “A dynamic filter module … produces filters conditioned on an input.”[20]라고 하며, 입력에 따라 달라지는 필터가 고정 필터보다 유연한 표현을 제공하여 성능을 높일 수 있음을 보였습니다. (예: 동적 필터를 이용한 비디오 프레임 예측 등에서 향상 결과 보고) → 문맥/입력 조건부 필터 생성은 모델의 적응성을 높이고, 다양한 상황에 대응하는 데 유리하다는 일반 원리입니다. - HyperNetworks 역시 “use a hypernetwork to generate weights for another neural network.”[21]라 하여, 한 네트워크의 출력을 다른 네트워크의 가중치로 생성하면 매개변수 효율을 높이면서 성능 향상을 가져올 수 있다고 합니다. → 즉, 조건부 가중치 생성을 통해 표현력 증대와 효율 개선을 달성하는 사례로, CTSF의 교차 연결도 일종의 hypernetwork 개념을 활용하고 있습니다.

[모델 조작]: - 원안 (Dynamic): 기존 CTSF의 CrossHyperConv 모듈 그대로 사용합니다. GRU 경로의 hidden state (혹은 CNN 경로 출력)을 입력으로 받아 계산된 계수로 CNN 쪽 활성화를 재가중하는 입력 의존적 결합이 수행됩니다. - 대조군 (Static): 교차 연결을 입력 불변의 고정 가중치 결합으로 바꿉니다. 구현은 두 가지 가능: (i) 1×1 Conv 고정: 동적 hypernetwork를 동일 채널 수의 1×1 convolution으로 대체하여, 학습은 하지만 시간에 따라 값이 변하지 않는 고정 결합으로 만듭니다. 또는 (ii) 학습가능 스칼라 게이트: 각 경로 출력에 대해 하나의 학습 파라미터(스칼라)를 두어 그 비율로 섞는 방식. 둘 중 어떤 방식을 써도 무방하나, 파라미터/FLOPs 수를 Dynamic과 ±3% 이내로 맞추도록 채널 폭 등을 조정합니다 (B1 실험으로 사전 검증). - 설정: 나머지 하이퍼파라미터, 학습 조건 (HP2) 동일. 단지 교차 모듈이 dynamic vs static으로 다를 뿐입니다.

[평가 지표 및 분석]: - 주요 지표: RMSE, MAE 등을 비교하여 전반적인 예측 성능 차이를 확인합니다. Dynamic이 Static보다 낮은 오류를 보여야 합니다. - 직접 지표: Dynamic의 이점은 시간대별 민감한 조정과 급변 대응으로 나타날 것이므로, TOD 민감도 지표와 피크 검출/시차 지표를 중점적으로 봅니다. 두 모델 모두 일정 부분 시간대에 반응하겠지만, Dynamic 쪽에서 특히 ETTh2 등의 데이터에서 피크 검출 능력이 향상되고 반응 시차가 짧아지는(즉, 더 신속히 반응) 양상을 기대합니다. Spearman 상관 등 경로 간 상관분석도 수행하여 dynamic일 때 CNN-GRU 경로 상관관계가 더 높거나 (협조적으로 움직임) 하는지를 살펴볼 것입니다. - 통계 검정: W1과 마찬가지로 대응 t-검정으로 유의미한 차이인지 확인합니다. 또, 특정 데이터/시간대에서 차이가 뚜렷한지를 추가 분석합니다 (예: ETTm2의 낮 시간대 성능 vs 정적 모델 비교 등).

판정 기준: Dynamic 모델이 Static 모델보다 RMSE, MAE 모두 개선되고, TOD 민감도는 dynamic 쪽이 높게 (즉 시간대에 따라 가중치 잘 조정) 나타나며, 피크/시차 지표도 개선폭이 관찰되면 동적 설계의 승리로 판정합니다. 특히 ETTm2 (15분 간격) 데이터는 일중 변동이 커서 동적 적응의 효과가 클 것으로, ETTh2 (1시간 간격) 데이터는 피크 패턴이 뚜렷하여 피크 탐지 이득이 클 것으로 예상합니다.

[기대되는 해석]: - Static 결합에서는 교차 가중치가 모든 시점에 고정되므로, 시간대/상황 변화를 반영하지 못합니다. 이는 특정 시간 구간에서는 부적절한 가중치 적용으로 문맥 적응력이 저하되고 일부 패턴을 놓치는 결과로 이어집니다. 예를 들어 야간과 주간 수요 패턴이 다른데도 동일한 결합 비율을 쓰면 최적이 아닐 수 있습니다. - Dynamic 결합은 현재 GRU 상태에 맞추어 CNN 필터나 출력을 강조 혹은 완화하므로, 맥락에 따른 조정이 일어납니다. 급격한 상승 신호가 감지되면 GRU의 상태변화로 CNN 경로의 특정 필터 출력을 증폭시키고, 반대로 완만한 구간에서는 불필요한 과민 반응을 줄이는 식입니다. 그 결과 Static 대비 예측 오차를 줄이고, 극한 상황에 더 잘 대응하게 됩니다. - 본 실험이 통과되면, 동적 Hypernetwork 구성의 타당성이 입증되어 CTSF의 설계 원리가 강화됩니다. 반대로 차이가 미미하다면, simpler한 정적 설계로도 충분했을 가능성을 고려해야 합니다.

[결과 보고 형식]: - 표: Dynamic – Static의 ΔRMSE, ΔTOD 지표, Δ피크/시차 지표를 나열해 어떤 면에서 얼마나 향상되었는지 보여줍니다. - 그래프: 시간대별 필터 민감도 히트맵 등 시각화를 통해 Static 대비 Dynamic에서 필터 가중치가 어떻게 상황에 따라 달라지는지 한 사례를 제시합니다 (예: dynamic 모델의 layer별 gate 값이 24시간 주기로 어떻게 변동하는지).

W3 실험 – 데이터 구조에 따른 성능 원인 검증 (교란 시험)

[배경 및 필요성]: 본 실험은 앞선 데이터 분석에서 도출된 CTSF 모델의 데이터 적합성 가설을 원인적으로 확인(causal inference)하고자 하는 것입니다. 즉, “왜 ETTm2/ETTh2에서 성능이 특히 좋았는가?”를 데이터 특성 요소별로 직접 교란하여 확인합니다. 이는 CTSF 012 보고의 Data-Level Analysis가 상관관계 위주였다면, 이번에는 원인-결과 관계를 작게나마 실험적으로 보여주고자 함입니다. 실험 규모는 작지만 설계 적합성을 못박는 증거를 마련하는 것이 목표입니다.

W3은 두 부분으로 나뉩니다: - A4-TOD 실험: ETTm2 데이터의 일별 주기성을 교란하여 GRU→CNN 문맥→필터 경로의 이득이 줄어드는지 관찰. - A4-PEAK 실험: ETTh2 데이터의 국소 피크/급변 신호를 완화하여 CNN→GRU 모양→업데이트 경로의 이득이 감소하는지 관찰.

두 실험 모두 작은 데이터 변형을 가해 성능 변화를 보는 것으로, CTSF의 각 교차 경로가 해당 데이터의 특정 구조에 의존해 이득을 냈음을 검증하려 합니다.

A4-TOD 실험 (ETTm2 – 시간대 패턴 교란)

목적: ETTm2의 경우 일중 (하루 96포인트) 및 주중 패턴이 뚜렷하여 GRU 경로의 주기적 문맥을 CNN이 활용한 것이 성능 이득의 원천이라는 가설을 세웠습니다[22]. 이를 검증하기 위해 학습 시 데이터의 시간대 정보를 교란한 후 성능 변화를 관찰합니다. GRU→CNN 경로(문맥→필터/출력)의 효과가 줄어드는지 확인하는 것이 목표입니다.

근거 인용: Informer 논문에서 ETT 데이터셋을 소개하며 “{ETTh1, ETTh2} for 1‑hour‑level and ETTm1 for 15‑minute‑level.”[23]라고 명시했고, Nixtla에서도 “ETTm2 (freq: '15T') … at a fifteen minute frequency.”[24]라고 설명하듯 ETTm 시리즈는 세분화된 주기를 갖습니다. 또한 전력 부하 데이터는 “The power load follows … annual, weekly, and daily seasonality.”[25]라고 알려져 있듯 하루 주기의 반복 패턴이 예측에 중요합니다. 이러한 배경에서, CTSF의 GRU→CNN 교차경로가 일/주 주기의 문맥 신호를 필터 조정에 활용했을 가능성이 높습니다.

조작 방법: 학습 데이터의 시간대 정보를 인위적으로 교란합니다. 예를 들어 1일 주기 (96포인트) 단위로 시계열을 순환 시프트(roll)하여 날짜와 요일 정보를 어긋나게 하거나, 시간 축을 약간 뒤틀어 페이즈 재배열을 수행합니다. 구체적으로: 일부 배치는 1~2시간 정도 앞으로 당겨지거나 늦춰진 시계열로 학습시킵니다. 이렇게 하면 모델이 학습 시 일정한 시간대 패턴을 잡기 어렵게 됩니다. (또는 더 간단히, 입력 시각 피처를 임의 섞기 등 가능)

평가 및 판정: 교란을 가한 모델과 일반 모델의 성능(RMSE)을 비교합니다. 만약 교란으로 인해 CTSF의 문맥→필터 이득이 감소한다면, 다음과 같은 현상이 나타날 것입니다:

교차 연결 모드별 성능 격차 감소: 예컨대, 기존에는 both (양방향 교차) > gc_only (GRU→Conv만) > cg_only > none 순으로 성능이 좋았다면, 교란 후에는 그 차이가 줄어듭니다.

TOD 민감도 지표 감소: GRU→Conv 경로의 kernel-TOD distance correlation 등이 교란 전보다 유의하게 내려갈 것입니다.

전체 RMSE 상승: 특히 gc_only나 both 설정에서 성능 저하폭이 크게 나타나 none 설정과 차이가 좁혀지면, 해당 경로 이득이 줄었다고 해석할 수 있습니다.

이러한 변화(↑오차, ↓민감도, ↓이득)를 관찰하면, “ETTm2에서의 성능 이득은 일중 주기 신호를 활용했기 때문”이라는 원인적 주장을 강화할 수 있습니다.

A4-PEAK 실험 (ETTh2 – 급변 패턴 교란)

목적: ETTh2 데이터는 1시간 간격이라 급격한 변화(peaks & valleys)가 상대적으로 도드라지게 나타납니다. CNN 경로가 이러한 국소 급변 형태를 감지하여 GRU 상태 업데이트를 도운 것이 성능 이득의 원인이라는 가설을 검증합니다. 즉, CNN→GRU 경로(모양→업데이트)의 기여 원인을 확인합니다.

근거: ETTh(ETTh1/2)는 1-hour granularity라 15-min 데이터보다 급변이 덜 매끄럽게 나타납니다[26]. 일반적으로 전력 수요는 계절/주기 외에도 하루 중 피크와 저점을 형성하는 뚜렷한 패턴이 있습니다 (전력 부하 문헌 다수). 이러한 피크 패턴을 CNN이 감지하여 GRU의 망각 게이트 등을 조정함으로써 성능 향상을 이루었을 수 있습니다.

조작 방법: 입력 시계열을 약간 평활화하여 급변 단서를 약화시킵니다. 예컨대 Savitzky–Golay 필터나 이동 중앙값 필터를 적용해, 원 데이터의 피크尖 / 꼬임 급변 부분을 완만하게 만듭니다. 중요한 것은 신호의 주요 추세는 보존하되 급작스런 변화 폭을 줄이는 것입니다 (참고: 파라미터는 변화량의 ±10% 정도 감소를 목표로 설정). 이렇게 학습하면 모델은 예측 시 극단 변화 감지 신호가 줄어들게 됩니다.

평가 및 판정: 교란 전후 모델의 피크 반응 지표 변화를 확인합니다. 예상되는 결과:

cg_event_gain↓: Conv→GRU 경로를 통해 얻는 이벤트 게인 (예: CNN이 감지한 이벤트로 GRU 출력이 개선되는 정도)이 줄어듭니다.

cg_bestlag 변화: Conv→GRU 사이의 최대 상관 시차(best lag)의 절대값이 증가(더 느려짐)할 수 있습니다. 이는 원래는 CNN 신호가 발생하고 곧바로 GRU가 반응했는데, 평활화 후에는 반응이 지연될 수 있음을 뜻합니다.

cg_spearman_mean↓: Conv 출력과 GRU state 간 순위상관이 낮아집니다, 즉 두 경로의 상호작용 일치도가 떨어집니다.

전체 성능: cg_only나 both 설정의 RMSE 이득이 감소하여, baseline과 큰 차이 없거나 일부 반전될 수 있습니다.

위 변화들이 관찰된다면, “ETTh2에서 모델 성능 이득은 국소 피크/변화 패턴을 활용한 덕분”이라는 해석을 강하게 뒷받침하게 됩니다.

비고: W3 (A4) 실험은 필수는 아니지만 권장되는 보강 실험입니다. 만약 앞선 W1, W2, W4, W5 결과와 기존 상관분석만으로도 충분히 설득력이 있다면 생략 가능하나, ETTm2/ETTh2에서 왜 설계 적합성이 높은지를 한 장의 그림으로 명확히 보여줄 수 있다는 점에서 유용합니다. 규모가 작고 추가 학습이 필요하므로, 시간적 여유와 자원 상황에 따라 시행을 결정합니다.

W4 실험 – 교차 층 기여도 분석 (Shallow/Mid/Deep)

[배경 및 필요성]: 교차 연결이 어느 계층에서 가장 이득을 주는가? 하는 질문은 모델 설계 최적화에 중요합니다. 만약 특정 층의 교차만으로도 충분하다면 모델을 단순화할 수 있고, 반대로 특정 층의 교차는 불필요하다면 제거를 고려할 수 있습니다. W4 실험은 얕은 층, 중간 층, 깊은 층 교차 연결 중 어떤 부분이 성능에 기여하는지 파악하여 설계 가이드라인을 얻고자 합니다. 이는 Cross-Stitch 논문의 “각 층마다 효과가 다르다”는 언급과도 관련됩니다[8].

[실험 목적]: Shallow-only, Mid-only, Deep-only 교차 연결 모델들을 만들어 비교합니다. 즉, 세 가지 실험: - 얕은 초기 몇 개 층에만 교차 연결을 남기고 이후 모두 OFF - 중간 일부 층에만 교차 ON - 가장 깊은 몇 개 층에만 교차 ON 각 경우 성능 변화를 측정하여, 어느 부분의 교차가 가장 효과적인지 알아냅니다. 이를 통해 CTSF 모델의 교차 설계 최적화에 대한 통찰을 얻습니다.

[이론적 근거]: Cross-Stitch Networks에서도 “At each layer... (층별 결합의 효과)”를 강조했지만, 실제로는 작업에 따라 최적 층이 다를 수 있음을 보여준 바 있습니다[27][28]. 우리의 경우도 데이터 특성에 따라 얕은 층(저수준 특징) vs 깊은 층(고수준 추세) 중 어디서 결합하는 게 유리한지 다를 수 있습니다. 가설적으로: - ETTm2(15분간격, 변동 많음): 깊은 층 교차가 더 중요할 수 있음 – 장기 추세를 잡아가는 후반에서 교차해야 효과적. - ETTh2(1시간간격, 주기 뚜렷): 얕은/중간 층 교차가 중요 – 초반에 계절성 등 신호를 같이 학습시키는 게 도움.

이러한 가설을 실험으로 검증하려는 것입니다.

[모델 조작]: - Shallow-only: 예를 들어 4개 블록 중 1~2층에만 교차 ON, 3~4층은 교차 OFF. - Mid-only: 2~3층에만 ON, 나머지 OFF. - Deep-only: 마지막 1~2개 층(예: 3~4층)에만 ON, 앞부분 OFF. - (정확한 구분은 전체 층 수에 따라 조정; CTSF 기본이 4개 block이라 가정) - 모두 양방향 교차는 유지 (ON 되는 층에서는 GRU→CNN, CNN→GRU 둘 다 활성). HP2 동일 적용.

[평가 및 분석]: - 각 조건별 RMSE, MAE를 기본 모델(both all-layer)과 비교하여 성능 감소량을 평가합니다. 어느 조건에서 감소가 가장 적은지가 중요 포인트입니다. - TOD 지표, 피크/시차 지표도 계산하여, 예컨대 얕은 층 교차만 있을 때 vs 깊은 층 교차만 있을 때 어떤 지표가 더 유지되는지를 봅니다. - 분석 초점: ETTm2에서 deep 교차만 남겨도 성능이 괜찮다면 deep쪽이 핵심, 반면 ETTh2에서는 shallow 쪽이 핵심… 등의 패턴을 찾습니다. - 통계적으로 RMSE 차이를 95% 신뢰구간으로 비교하고, 유의한 차이면 언급합니다.

판정 기준:

한 조건에서만 성능이 현저히 낮다면, 그 부분의 교차가 매우 중요하다는 뜻입니다.

예를 들어 ETTm2에서 Deep-only가 다른 조건보다 월등히 나으면 “깊은 층 교차 기여도가 크다”라고 판정.

ETTh2에서 Shallow-only가 좋으면 “초기 교차 중요” 판정.

만약 all-layer보다 특정 조건이 더 좋다면 (가능성은 낮지만) 불필요한 교차가 있었다는 의미도 될 수 있습니다.

[기대 해석]: - 예상대로라면, ETTm2 (여러 주기, 불규칙 변동 혼합)에서는 후반부 교차가 GRU의 장기 추세와 CNN의 누적패턴을 맞춰주는 역할로 중요할 것입니다. 반면 ETTh2 (명확한 일/주기)에서는 초~중반 교차로 기본 패턴을 함께 학습하는 게 더 중요할 수 있습니다. - 이 결과는 새로운 데이터에 모델 적용 시 교차를 어디에 배치/집중해야 할지 지침을 줍니다. 예컨대 “데이터에 강한 계절성 → 얕은 층부터 특성 결합 강화”, “데이터 변동 잦음 → 후반 교차 강화” 등으로 응용 가능할 것입니다. - 또한, 불필요한 교차가 있다면 해당 부분은 모델 단순화를 통해 경량화할 수 있는 여지가 있습니다.

[보고 형식]: - 표: 데이터셋별로 Shallow-only, Mid-only, Deep-only의 RMSE 및 주요 지표를 baseline과 함께 나열해 한눈에 비교. - 그래프: 라인 차트로 층별 교차 개수(혹은 위치)에 따른 성능 변화를 나타냅니다. 예: x축 = 교차 적용 범위(얕은→깊은), y축 = RMSE (낮을수록 좋음), 곡선 형태로 최적 범위를 식별.

W5 실험 – 게이트 고정 시험 (동적→정적 중간 형태)

[배경 및 필요성]: W2에서 동적 vs 정적 전체 구조를 비교했다면, W5는 동적 구조 내에서의 미세 분석입니다. 동적 하이퍼네트워크가 성능 향상에 얼마나 기여하는지 정량적 순효과를 확인하기 위해, 학습된 동적 게이트를 고정시켜 보는 실험입니다. 이는 일종의 사후 해석(post-hoc) 실험으로, “동적 적응성 자체가 없다면 성능이 얼마나 떨어지는가?”를 봄으로써 dynamic 구문의 순이익을 가늠할 수 있습니다.

[실험 목적]: 학습을 끝낸 CTSF 모델에서 교차 게이트(gating)의 동적 변동성을 제거한 채로 성능을 측정합니다. 즉, 동적→정적의 중간 케이스를 실험하여, 동적 적응성의 중요도를 확인합니다.

[이론적 근거]: 근거는 W2와 동일한 맥락으로, Dynamic Filter, HyperNetwork의 유용성을 들 수 있습니다[20][21]. 차이는, 여기서는 학습된 모델 내부에서 게이트 변수를 고정해보는 것이므로, 가중치를 다시 학습하진 않지만 inference 단계에서 동적 기능만 OFF하는 특수 실험입니다. 이를 통해 “학습된 dynamic이 얼마나 역할을 했는가”를 직접 확인할 수 있습니다.

[모델 조작]: - 완전 학습된 CTSF 모델 (both 설정)을 준비합니다. - 각 교차 계층의 게이트 파라미터 출력 분포를 분석하여, 평균값을 계산합니다. (예: CrossHyperConv 모듈 내부에서 time-step마다 생성되는 α, β 등의 평균) - 모델을 수정하지 않고, 추론 시에 한해 각 시간 스텝의 게이트를 그 평균값으로 고정하여 forward를 진행합니다. - 즉, dynamic한 변화 대신 항상 평균 게이트만 적용된 상태로 전체 테스트 세트를 통과시켜 성능을 재평가합니다. (학습은 하지 않고 평가만 함) - 이 작업은 구현 시 간단히, 코드 상에서 gating 텐서를 불러온 뒤 tensor.fill_(mean)으로 채우거나 하는 식으로 처리합니다.

[평가 및 판정]: - TOD 민감도와 피크 반응 지표를 고정 전후로 비교합니다. 만약 게이트 고정으로 성능이 떨어진다면 동적 적응이 유효했다는 의미입니다: - RMSE 증가: 게이트 고정 모델의 RMSE가 원래 모델보다 상승 (악화)할 것입니다. - TOD 민감도 감소: 원래 dynamic 모델에서 높게 나타났던 시간대별 필터 반응성이, 게이트 고정으로 줄어듭니다. - 피크 검출 감소: 피크 반응 지표 (event gain 등)도 저하. - 이 변화들이 유의미해야 합니다 (예: RMSE 상승 폭의 95% CI가 0을 상회). - 판정: 위 변화가 뚜렷하면 “동적 게이트의 샘플별 변화가 성능에 기여했다”라고 결론짓습니다. 만약 변화가 미미하다면 dynamic 효과가 생각만큼 크지 않았을 수도 있지만, 일반적으로는 어느 정도 차이가 날 것으로 예상합니다.

[기대 해석]: - 게이트를 고정한다는 것은, 일종의 CTSF를 static 모드로 강제하는 효과가 있습니다 (하지만 가중치 자체는 dynamic 학습된 값이라 W2의 static 모델과는 다름). - 이때 성능이 눈에 띄게 나빠진다면, 이는 실제 각기 다른 상황에서 게이트가 제 역할을 했음을 의미합니다. 즉, 동적 적응성의 순효과를 수치로 보여주는 셈입니다. - 특히, 시간별 패턴이 다양한 데이터일수록 게이트 고정 시 타격이 클 것입니다. 예를 들어 Weather나 ECL 같은 데이터에도 적용해볼 수 있으며, 거기서도 확인된다면 general하게 dynamic의 가치가 증명됩니다. - 이 실험은 독립 변인 통제가 어렵지만 (학습 관여 없이 inference만 바꾸는 것이라), “dynamic이 없다면 이 정도 나빠진다”는 메시지를 주기에 유용합니다.

[보고 형식]: - 표: 원래 모델 vs 게이트평균 고정 모델의 RMSE, MAE, TOD, 피크 지표를 비교. - 도식: 간단한 막대그래프 등으로 RMSE 상승폭을 보여주거나, 게이트 분포를 그림으로 삽입하여 게이트가 얼마나 다양하게 쓰였는지 시각화합니다.

실험 결과 로그(.csv) 저장 조건 및 평가 지표 목록

실험 로그 저장: 모든 실험에서는 각 설정별 최종 결과를 CSV 로그 파일로 저장합니다. 예를 들어 데이터셋별, Horizon별, seed별 실행에 대해 한 행(row)씩 결과를 기록하고, 열에는 설정과 지표들이 포함됩니다. 로그 파일은 results.csv (또는 results_W1.csv 등 실험별 파일) 형태로, 매 실험 실행 완료 시 자동으로 추가 기록하도록 합니다. 덮어쓰기를 피하기 위해 고유 모드명 (e.g. both, gc_only 등)과 타임스탬프 등을 키로 저장합니다.

저장 조건: - 학습이 정상 완료되어 테스트 세트에 대한 평가까지 끝난 경우에만 해당 run의 결과를 CSV에 기록합니다. 중간 epoch 결과나 validation 결과 등은 로그 파일에 기록하지 않습니다 (필요시 별도 파일 사용). - 하나의 설정 조합(예: 특정 모델 모드 + 특정 데이터셋+Horizon + seed)에 대해 1회 기록하며, 반복 실험 시 평균이나 표준편차는 별도 처리합니다. - 로그 파일은 ,로 구분된 UTF-8 CSV로 저장하고, 헤더 행에 지표 이름들을 명시합니다.

기준 지표 목록: (괄호 안은 의미 설명) - RMSE: Root Mean Square Error, 실제값 스케일의 RMSE (모델 평가 주 지표). - MAE: Mean Absolute Error, 실제값 스케일 MAE. - mse_std: MSE on standardized data (학습 시 정규화한 데이터 기준 MSE, 내부 손실과 대응). - mse_real: MSE on real scale (실제 단위 데이터에서의 MSE). - std_MAE: MAE on standardized scale (표준화 데이터 기준 MAE). - real_MAE: MAE on real scale (실제값 MAE, 통상 MAE와 동일). - r2: R-squared (결정계수) – 일부 회귀평가용으로 저장 (필요시). - pearson_r: Pearson 상관계수 (예측 vs 실제). - spearman_r: Spearman 순위상관 (예측 vs 실제) – 순위 기반 상관도로 비선형 관계 평가. - TOD sensitivity: 시간대 민감도 지표들 – 예를 들어, - gc_kernel_tod_dcor: GRU→Conv 생성 커널 vs 시간(daytime)의 distance correlation (값 클수록 시간대 따라 필터 변화가 뚜렷함)[29], - gc_feat_tod_dcor: GRU→Conv 출력 특징 vs 시간의 dCor 등. (각각 문맥 경로 출력이 시간 패턴에 얼마나 민감한지 나타냄) - peak response metrics: 피크 반응 관련 – - cg_event_gain: Conv→GRU 경로로 인해 얻는 이벤트 검출 이득(예: 피크를 얼마나 추가로 잘 맞추게 되었는지)[30][31], - cg_event_hit: 특정 임계 이상 피크를 맞춘 빈도, - cg_maxcorr: Conv vs GRU 출력 간 최대 상관값[32][33], - cg_bestlag: 그 때의 시차 (lag)[32][33]. - response delay: 위 bestlag를 의미있게 발췌하여 명시적으로 표기할 수도 있습니다 (양수이면 GRU 뒤짐: 반응 지연). - grad_norm 등 학습 과정 지표도 일부 기록 가능 (모델 안정성 참고용).

⬆️ 위 지표들은 코드 구현에 따라 명칭이 조금 다를 수 있으나, RMSE, MAE는 기본이고 추가로 정의된 직접 근거 지표들(TOD 관련, event 관련, 상관계수 등)이 모두 로그에 포함됩니다. 각 지표의 정의는 CTSF-V1 코드에 문서화되어 있으며, 추후 분석 시 해당 CSV를 불러 적절한 통계 처리/시각화를 진행합니다.

편의성 코드 구성 및 필요성

CTSF-V1 구현에는 실험을 원활히 하기 위한 여러 편의 기능이 포함되어 있으며, W 실험들을 수행하기 위해서도 이러한 편의성 코드가 필수적입니다. 주요 구성 요소는 다음과 같습니다:

Progress Bar (tqdm): 데이터 로딩 및 매 epoch 학습 진행을 한눈에 볼 수 있도록 tqdm을 사용한 진행 표시막대를 구현했습니다[34][35]. 대량 실험 시 각 run의 진행 상황을 모니터링하고 남은 시간을 예측하는 데 도움을 줍니다.

안전한 상관 계산 (safe correlation): 상관계수 등을 계산할 때 0으로 나누는 경우나 상수 시계열 등 예외 상황을 처리하기 위해 _safe_corr 함수를 구현했습니다[36][31]. 이를 통해 NaN 무시나 값 clamp 등을 수행하여, 실험 중 상관 관련 지표 계산이 중단되지 않고 안정적으로 이루어집니다.

중단 후 이어하기 (resume): 여러 실험(job)을 연속 수행 중 외부 요인으로 중단되더라도 이어서 시작할 수 있도록 체크포인트 & 플래그 관리 기능이 있습니다. run_dir_switch_suite_plan 함수에서 진행 상황을 기록하고, resume_mode 설정 시 이전에 완료된 조합을 건너뛰도록 구현되어 있습니다[37][38]. 이로써 수백 회 실험을 며칠에 걸쳐 수행할 때도 효율을 높입니다.

중간 결과 저장 및 삭제: 메모리 관리와 저장소 부담을 줄이기 위해 중간 모델 파일이나 일시 결과를 주기적으로 저장/삭제하는 로직이 포함되어 있습니다. 예를 들어, epoch별 best 모델을 best-CTSF-V1.pt 등에 저장하고, 새로운 best가 나오면 이전 파일은 삭제하거나 덮어쓰는 식입니다[39][40]. 또, 큰 결과 배열은 numpy로 디스크에 저장 후 필요 시 불러오고 메모리에서 제거하는 방식도 사용합니다.

GPU 메모리 정리: PyTorch 사용 시 GPU 메모리 누수가 발생하지 않도록, 매 실험 끝날 때 torch.cuda.empty_cache() 등을 호출하여 캐시를 비웁니다. 또한 eval 후 del을 통해 불필요한 텐서를 해제하고, Python GC(가비지 컬렉터)를 수동 호출하여 메모리를 회수하는 코드를 추가했습니다. 이를 통해 연속 실험 시 CUDA OOM 오류를 예방합니다.

기타:

Gradient Clipping: 학습 안정화를 위해 gradients를 클리핑하는 기능이 포함되어 있습니다 (예: clip_grad_norm_으로 폭발 방지)[41].

로그 및 가시화: matplotlib를 이용해 학습 곡선을 그리거나, 중요한 통계 (예: α 게이트 값 분포) 출력 기능이 있어 실험 중 바로바로 확인 가능합니다.

Hooks 구현: 내부 동작 추적을 위해 forward 훅을 사용, 각 계층 출력이나 중요 텐서를 저장하는 기능도 있습니다. 이를 통해 Direct Evidence 지표 (예: conv/GRU 출력, kernel 등) 계산에 활용합니다[42][32].

멀티프로세싱 옵션: DataLoader에 num_workers 조정 등으로 I/O 병목을 줄이고 GPU 유휴를 방지합니다.

이러한 편의성 코드는 W 실험 수행을 자동화하고 안정성을 높이는 핵심 요소입니다. 특히 W 실험은 설정 조합이 많고 반복 실험이 필요하므로, 재현성과 효율성을 위해 위 기능들이 사전에 잘 구비되어야 합니다. CTSF-V1 코드베이스에는 이미 대부분 구현되어 있으므로, 이를 적극 활용하여 실험을 진행합니다.

실험 환경 및 재현 조건

모든 실험은 다음 환경에서 수행되고 재현 가능합니다:

플랫폼: Ubuntu Linux 20.04 LTS (64-bit) 서버 환경. (POSIX 호환 OS면 무방하나, Windows에서는 경로 처리 등 추가 수정 필요할 수 있음)

프로그래밍 언어 및 라이브러리: Python 3.9 이상. 주요 라이브러리는 PyTorch 1.13 (또는 2.x 호환)[43], CUDA Toolkit 11.x, NumPy 1.21+, Pandas (CSV 처리 용도), tqdm, matplotlib 등이 사용됩니다. 필요 시 scikit-learn 등도 설치 (예: Spearman 계산 검증용).

하드웨어(GPU): NVIDIA GPU (CUDA Compute Capability 7.0+) – 예시: NVIDIA GeForce RTX 3090 (24GB) 또는 동급 이상의 VRAM을 가진 GPU에서 실험. 본 실험들은 대부분 단일 GPU로 수행 가능하며, 멀티-GPU 병렬은 사용하지 않았습니다 (torch.cuda.set_device(0)로 고정 사용)[44].

메모리: GPU 12GB 이상 (24GB 권장) for batch size 및 모델 적재. 시스템 RAM은 32GB 이상 권장 (데이터셋 및 중간 결과 적재).

정밀도(Precision): 연산은 기본적으로 FP32 (32-bit 부동소수점) 정밀도로 수행합니다. PyTorch의 Automatic Mixed Precision(AMP)나 FP16은 사용하지 않았습니다. 단, NVIDIA Ampere 아키텍처에서는 기본 설정에 따라 TF32(10비트 정밀) 매트멀 연산이 사용될 수 있으나, 특별히 끄지 않았으므로 내재적으로 사용됩니다. 이는 reproducibility에 큰 영향이 없으나 필요하면 torch.set_float32_matmul_precision('high')로 통제 가능합니다.

재현을 위한 시드: 코드에서 난수 시드를 고정하였으며 (예: torch.manual_seed, np.random.seed, random.seed 모두 동일 값)[45], 이를 README에 명시했습니다. 따라서 동일 환경에서 실행하면 결과 재현이 가능합니다. 다만 GPU 연산 비결정성(cudnn 비동기 등)은 torch.backends.cudnn.deterministic = True 설정으로 제어하였습니다.

기타 설정:

PyTorch torch.backends.cudnn.benchmark = False로 설정하여 레이어별 실행 최적화가 시드간 변화 유발하지 않도록 했습니다.

학습 Hyperparameter (learning rate, batch size=32, epochs=10 등) 상세 내역과, 데이터전처리(정규화 방식 등)는 깃허브 exp-plan의 README에 기술하여 재현성을 담보합니다.

사용한 데이터셋 (ETT, Weather 등)은 Nixtla에서 제공하는 공개 세트를 이용하며, 동일 splits (Train/Val/Test)로 실험합니다.

이상의 조건을 만족하면, 본 문서에 서술된 W1~W5 실험을 누구나 동일한 결과로 재현할 수 있습니다. 환경 세팅 및 의존 라이브러리 버전은 추후 requirements.txt로 정리하여 실험 저장소에 포함할 예정입니다.

---

## References

- [1] CTSF 012.pptx — *(local file)* 
- [2] CTSF 012.pptx — *(local file)* 
- [3] CTSF 012.pptx — *(local file)* 
- [4] CTSF 012.pptx — *(local file)* 
- [5] CTSF 012.pptx — *(local file)* 
- [6] CTSF Summary 002.pdf — *(local file)* 
- [7] CTSF Summary 002.pdf — *(local file)* 
- [8] ri.cmu.edu — https://www.ri.cmu.edu/pub_files/2016/6/multi-task.pdf
- [9] CTSF 012.pptx — *(local file)* 
- [10] CTSF 012 - 복사본.pdf — *(local file)* 
- [11] CTSF 012.pdf — *(local file)* 
- [12] CTSF 012.pdf — *(local file)* 
- [13] CTSF 012.pdf — *(local file)* 
- [14] CTSF 012.pdf — *(local file)* 
- [15] CTSF 012.pdf — *(local file)* 
- [16] CTSF 012.pdf — *(local file)* 
- [17] CTSF 012.pdf — *(local file)* 
- [18] ri.cmu.edu — https://www.ri.cmu.edu/pub_files/2016/6/multi-task.pdf
- [19] Feature-Dependent Cross-Connections in Multi-Path Neural Networks — https://arxiv.org/abs/2006.13904
- [20] Dynamic Filter Networks — http://papers.neurips.cc/paper/6578-dynamic-filter-networks.pdf
- [21] HyperNetworks — https://deepsense.ai/wp-content/uploads/2023/03/1609.09106.pdf
- [22] CTSF 012.pdf — *(local file)* 
- [23] Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting — https://cdn.aaai.org/ojs/17325/17325-13-20819-1-2-20210518.pdf
- [24] Long-Horizon Original Datasets - Nixtla — https://nixtlaverse.nixtla.io/datasetsforecast/long_horizon2.html
- [25] Electricity demand changes in predictable patterns - U.S. Energy Information Administration (EIA) — https://www.eia.gov/todayinenergy/detail.php?id=4190
- [26] Example Data - Nixtla - Nixtlaverse — https://nixtlaverse.nixtla.io/neuralforecast/utils.html
- [27] ri.cmu.edu — https://www.ri.cmu.edu/pub_files/2016/6/multi-task.pdf
- [28] ri.cmu.edu — https://www.ri.cmu.edu/pub_files/2016/6/multi-task.pdf
- [29] CTSF Summary 002.pdf — *(local file)* 
- [30] CTSF-V1.ipynb — *(local file)* 
- [31] CTSF-V1.ipynb — *(local file)* 
- [32] CTSF-V1.ipynb — *(local file)* 
- [33] CTSF-V1.ipynb — *(local file)* 
- [34] CTSF-V1.ipynb — *(local file)* 
- [35] CTSF-V1.ipynb — *(local file)* 
- [36] CTSF-V1.ipynb — *(local file)* 
- [37] CTSF-V1.ipynb — *(local file)* 
- [38] CTSF-V1.ipynb — *(local file)* 
- [39] CTSF-V1.ipynb — *(local file)* 
- [40] CTSF-V1.ipynb — *(local file)* 
- [41] CTSF-V1.ipynb — *(local file)* 
- [42] CTSF-V1.ipynb — *(local file)* 
- [43] CTSF-V1.ipynb — *(local file)* 
- [44] CTSF-V1.ipynb — *(local file)* 
- [45] CTSF-V1.ipynb — *(local file)* 
