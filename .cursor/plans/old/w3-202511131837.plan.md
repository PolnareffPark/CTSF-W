<!-- 9a93c5ab-08ec-4754-a148-7a9d1165d777 46d273f6-0b78-42f0-869d-6da52dc5531b -->
# W3 Experiment 최종 통합 계획

## 1. 두 버전 비교 분석

### 버전 1 (라인 1-387, 기존 수정본)

**장점:**

- `_create_model()` 메서드 존재 → BaseExperiment 초기화 성공
- 함수 호출 시그니처 정확 (w3_plotting_metrics.py와 일치)
- `_append_or_update_results` 로직이 인라인으로 완전히 구현됨
- results_W3.csv에 모든 지표 저장 (cg_, gc_ 등)

**단점:**

- import 중복 (build_test_tod_vector 두 번 import)
- 교란 로직 복잡 (여러 헬퍼 메서드로 분산)
- 코드 중복 (경로 생성, ctx 딕셔너리 등)

### 버전 2 (라인 389-781, 신규 설계)

**장점:**

- 깔끔한 구조 (유틸 함수 상단 분리)
- `@torch.no_grad()` 데코레이터로 성능 최적화
- `_detect_layout()`, `_moving_avg_1d()` 등 명확한 함수명
- `_ctx()` 헬퍼 메서드로 중복 제거
- hp2_config.yaml 연동 구조 (데이터셋별 설정)

**단점 (치명적):**

- `_create_model()` 메서드 누락 → BaseExperiment.__init__에서 NotImplementedError 발생
- `self._append_or_update_results()` 호출하지만 정의 안 됨 → AttributeError 발생
- `compute_and_save_w3_gate_tod_heatmap()`에 `tod_vec` 누락 → TypeError 발생
- `rebuild_w3_forest_summary()`에 `pair_map` 인자 전달하지만 함수 시그니처에 없음
- `rebuild_w3_perturb_delta_bar()`에 `out_dir`, `pair_map` 인자 전달하지만 함수 시그니처에 없음

### 함수 시그니처 확인 결과

```python
# w3_plotting_metrics.py 실제 시그니처
compute_and_save_w3_gate_tod_heatmap(ctx, hooks_data, tod_vec, dataset, out_dir, amp_method="range")
rebuild_w3_forest_summary(detail_csv, summary_csv, gate_tod_summary_csv=None, group_keys=(...))
rebuild_w3_perturb_delta_bar(results_csv, detail_csv, summary_csv)  # pair_map, out_dir 없음
```

## 2. 최종 통합 전략

**기본 방침:** 버전 2의 깔끔한 구조를 기반으로, 버전 1의 필수 요소 통합

## 3. 상세 구현 계획

### Phase 1: 파일 상단 (import 및 유틸 함수)

**삭제:** 라인 389-781 전체 (중복 코드 제거)

**수정:** 라인 1-36 (import 및 상수)

```python
from __future__ import annotations

import copy
import math
import os
from pathlib import Path
from typing import Any, Dict, List, Tuple, Optional

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F

from .base_experiment import BaseExperiment
from data.dataset import build_test_tod_vector
from models.ctsf_model import HybridTS
from utils.direct_evidence import evaluate_with_direct_evidence
from utils.experiment_metrics.all_metrics import compute_all_experiment_metrics
from utils.experiment_plotting_metrics.w3_plotting_metrics import (
    save_w3_forest_detail_row,
    rebuild_w3_forest_summary,
    compute_and_save_w3_gate_tod_heatmap,
    compute_and_save_w3_gate_distribution,
    rebuild_w3_perturb_delta_bar,
)

RESULTS_ROOT = Path("results")
EXP_TAG = "W3"
MODES = ("none", "tod_shift", "smooth")
```

**추가:** 라인 37 이후 (버전 2의 유틸 함수 추가)

```python
# ------------------------------
# dataset별 TOD bin 가정값
# ------------------------------
def _infer_tod_bins(dataset: str) -> int:
    ds = (dataset or "").lower()
    if "ettm" in ds:    return 96
    if "etth" in ds:    return 24
    if "weather" in ds: return 144
    return 24

# ------------------------------
# 교란 파라미터 기본값
# ------------------------------
def _default_perturb_cfg(dataset: str) -> Dict[str, Any]:
    ds = (dataset or "").lower()
    if "ettm2" in ds:
        return dict(
            tod_shift=dict(max_shift=8),
            smooth=dict(kernel=3, alpha=0.25),
        )
    if "etth2" in ds:
        return dict(
            tod_shift=dict(max_shift=2),
            smooth=dict(kernel=5, alpha=0.35),
        )
    return dict(
        tod_shift=dict(max_shift=max(1, _infer_tod_bins(dataset)//48)),
        smooth=dict(kernel=3, alpha=0.25),
    )

# ------------------------------
# 유틸: 텐서 모양 & 시간축 판별
# ------------------------------
def _detect_layout(x: torch.Tensor) -> Tuple[int, int]:
    """
    입력 x의 시간축/채널축 추정.
    허용: (B, L, C) 혹은 (B, C, L).
    반환: (t_axis, c_axis)
    """
    assert x.dim() == 3, "W3 wrapper expects 3D input (B, L, C) or (B, C, L)."
    b, a1, a2 = x.shape
    if a1 >= a2:
        return 1, 2  # (B, L, C)
    else:
        return 2, 1  # (B, C, L)

def _moving_avg_1d(x: torch.Tensor, k: int, t_axis: int) -> torch.Tensor:
    """
    시간축 기준 1D 이동평균. 입력 x: (B, L, C) 또는 (B, C, L).
    """
    if k <= 1:
        return x
    if k % 2 == 0:
        k = k + 1
    
    # (B, C, L)로 정규화
    if t_axis == 1:
        x_nc_t = x.permute(0, 2, 1)
    else:
        x_nc_t = x
    
    b, c, L = x_nc_t.shape
    weight = torch.ones(1, 1, k, device=x_nc_t.device, dtype=x_nc_t.dtype) / float(k)
    x_flat = x_nc_t.reshape(b * c, 1, L)
    pad = k // 2
    x_pad = F.pad(x_flat, (pad, pad), mode="reflect")
    y = F.conv1d(x_pad, weight)
    y = y.reshape(b, c, L)
    
    if t_axis == 1:
        return y.permute(0, 2, 1)
    else:
        return y
```

### Phase 2: _W3PerturbWrapper 클래스

**교체:** 라인 42-157을 버전 2 스타일로 재작성

```python
class _W3PerturbWrapper(nn.Module):
    """
    학습 단계에서만 입력 x에 교란을 가하고 base 모델로 전달.
    평가 단계(eval)에서는 원본 입력을 그대로 사용.
    """
    def __init__(self, base: nn.Module, mode: str, dataset: str, perturb_cfg: Optional[Dict[str, Any]] = None):
        super().__init__()
        self.base = base
        self.mode = str(mode or "none")
        self.dataset = str(dataset or "")
        self.cfg = perturb_cfg.copy() if isinstance(perturb_cfg, dict) else _default_perturb_cfg(dataset)
        defaults = _default_perturb_cfg(dataset)
        for k, v in defaults.items():
            self.cfg.setdefault(k, v)
        self.tod_bins = _infer_tod_bins(self.dataset)

    def forward(self, x: torch.Tensor, *args, **kwargs):
        if (not self.training) or (self.mode == "none"):
            return self.base(x, *args, **kwargs)
        
        if self.mode == "tod_shift":
            x = self._apply_tod_shift(x)
        elif self.mode == "smooth":
            x = self._apply_smooth(x)
        return self.base(x, *args, **kwargs)

    def __getattr__(self, name: str):
        try:
            return super().__getattr__(name)
        except AttributeError:
            base = super().__getattribute__("base")
            if hasattr(base, name):
                return getattr(base, name)
            raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")

    @torch.no_grad()
    def _apply_tod_shift(self, x: torch.Tensor) -> torch.Tensor:
        """
        시간축을 순환 이동(roll)하여 TOD 위상을 교란.
        """
        t_axis, _ = _detect_layout(x)
        max_shift = int(self.cfg.get("tod_shift", {}).get("max_shift", 1))
        if max_shift <= 0:
            return x
        
        s = torch.randint(-max_shift, max_shift + 1, (1,), device=x.device).item()
        if s == 0:
            s = 1 if max_shift >= 1 else 0
        if s == 0:
            return x
        
        dims = (t_axis,)
        return torch.roll(x, shifts=s, dims=dims)

    @torch.no_grad()
    def _apply_smooth(self, x: torch.Tensor) -> torch.Tensor:
        """
        시간축 이동평균으로 급변 단서 약화.
        """
        t_axis, _ = _detect_layout(x)
        k = int(self.cfg.get("smooth", {}).get("kernel", 3))
        alpha = float(self.cfg.get("smooth", {}).get("alpha", 0.25))
        if k <= 1 or alpha <= 0:
            return x
        y = _moving_avg_1d(x, k, t_axis)
        return (1.0 - alpha) * x + alpha * y
```

### Phase 3: W3Experiment 클래스

#### 3.1 **init** 메서드

**수정:** 라인 169-194

```python
class W3Experiment(BaseExperiment):
    """
    - BaseExperiment의 학습/평가 루틴을 그대로 사용
    - 모델만 W3 wrapper로 감싸 학습 단계에서 교란을 적용
    - 평가 직후 W3 전용 그림(summary/detail)과 results_W3.csv 저장
    """
    def __init__(self, cfg: Dict[str, Any]):
        cfg_local = copy.deepcopy(cfg or {})
        cfg_local.setdefault("experiment_type", EXP_TAG)
        cfg_local.setdefault("mode", "none")
        super().__init__(cfg_local)
        
        # wrapper로 교체
        dataset = str(self.cfg.get("dataset") or "")
        mode = str(self.cfg.get("mode") or "none")
        perturb_cfg = self.cfg.get("perturb_cfg") or _default_perturb_cfg(dataset)
        self.model = _W3PerturbWrapper(self.model, mode=mode, dataset=dataset, perturb_cfg=perturb_cfg)
        
        # 버퍼
        self._last_hooks_data: Dict[str, Any] = {}
        self._last_direct: Dict[str, Any] = {}
```

#### 3.2 _create_model 메서드 (필수!)

**유지:** 라인 196-199 (버전 1에서 가져옴)

```python
    def _create_model(self):
        """BaseExperiment가 요구하는 모델 생성"""
        return HybridTS(self.cfg, self.n_vars)
```

#### 3.3 _ctx 헬퍼 메서드 (추가)

**추가:** 새로운 메서드

```python
    def _ctx(self, dataset: str, horizon: int, seed: int, mode: str, 
             model_tag: str, run_tag: str, plot_type: str = "") -> Dict[str, Any]:
        return {
            "experiment_type": EXP_TAG,
            "dataset": dataset,
            "plot_type": plot_type,
            "horizon": int(horizon),
            "seed": int(seed),
            "mode": str(mode),
            "model_tag": str(model_tag),
            "run_tag": str(run_tag),
        }
```

#### 3.4 evaluate_test 메서드

**수정:** 라인 215-246을 버전 2 스타일로 간소화

```python
    def evaluate_test(self) -> Dict[str, Any]:
        try:
            tod_vec = build_test_tod_vector(self.cfg)
        except Exception:
            tod_vec = None
        
        direct = evaluate_with_direct_evidence(
            self.model,
            self.test_loader,
            self.mu,
            self.std,
            tod_vec=tod_vec,
            device=self.device,
            collect_gate_outputs=True,
        )
        
        hooks = direct.pop("hooks_data", None) or {}
        
        try:
            exp_specific = compute_all_experiment_metrics(
                experiment_type=EXP_TAG,
                model=self.model,
                hooks_data=hooks if hooks else None,
                tod_vec=tod_vec,
                direct_evidence=direct,
                perturbation_type=self.cfg.get("mode", "none"),
            )
            direct.update(exp_specific or {})
        except Exception:
            pass
        
        self._last_hooks_data = copy.deepcopy(hooks)
        self._last_direct = copy.deepcopy(direct)
        return direct
```

#### 3.5 _after_eval_save 메서드 (핵심 수정)

**대폭 수정:** 라인 249-345

```python
    def _after_eval_save(
        self,
        dataset: str, horizon: int, seed: int, mode: str,
        direct: Dict[str, Any], hooks: Dict[str, Any],
        model_tag: str, run_tag: str,
    ) -> None:
        # 경로 생성
        results_root = RESULTS_ROOT
        fdir = results_root / f"results_{EXP_TAG}" / dataset / "forest_plot"
        hdir = results_root / f"results_{EXP_TAG}" / dataset / "gate_tod_heatmap"
        ddir = results_root / f"results_{EXP_TAG}" / dataset / "gate_distribution"
        fdir.mkdir(parents=True, exist_ok=True)
        hdir.mkdir(parents=True, exist_ok=True)
        ddir.mkdir(parents=True, exist_ok=True)
        
        # ctx 생성 (헬퍼 사용)
        ctx = self._ctx(dataset, horizon, seed, mode, model_tag, run_tag)
        
        # 1) Forest detail 저장
        rmse_real = float(direct.get("rmse") or (direct.get("mse_real", 0.0) ** 0.5) or 0.0)
        mae_real = float(direct.get("mae") or direct.get("mae_real") or 0.0)
        save_w3_forest_detail_row(
            ctx={**ctx, "plot_type": "forest_plot"},
            rmse_real=rmse_real,
            mae_real=mae_real,
            detail_csv=fdir / "forest_plot_detail.csv",
        )
        
        # 2) Gate-TOD Heatmap 저장
        # tod_vec 재생성 (필수 인자)
        try:
            tod_vec = build_test_tod_vector(self.cfg)
        except Exception:
            tod_vec = None
        
        compute_and_save_w3_gate_tod_heatmap(
            ctx={**ctx, "plot_type": "gate_tod_heatmap"},
            hooks_data=hooks,
            tod_vec=tod_vec,  # 필수!
            dataset=dataset,
            out_dir=hdir,
            amp_method="range",  # 기본값 명시
        )
        
        # 3) Gate Distribution 저장
        compute_and_save_w3_gate_distribution(
            ctx={**ctx, "plot_type": "gate_distribution"},
            hooks_data=hooks,
            out_dir=ddir,
        )
        
        # 4) results_W3.csv 저장 (버전 1의 로직 사용)
        def _append_or_update_results(csv_path, row, subset):
            path = Path(csv_path)
            path.parent.mkdir(parents=True, exist_ok=True)
            new = pd.DataFrame([row])
            if path.exists():
                old = pd.read_csv(path)
                for c in new.columns:
                    if c not in old.columns:
                        old[c] = np.nan
                for c in old.columns:
                    if c not in new.columns:
                        new[c] = np.nan
                df = pd.concat([old, new], ignore_index=True)
                df.drop_duplicates(subset=subset, keep="last", inplace=True)
                tmp = path.with_suffix(path.suffix + ".tmp")
                df.to_csv(tmp, index=False)
                tmp.replace(path)
            else:
                new.to_csv(path, index=False)
        
        row = {
            "dataset": dataset, "horizon": horizon, "seed": seed, "mode": mode,
            "model_tag": model_tag, "experiment_type": EXP_TAG,
            "mse_real": float(direct.get("mse_real", np.nan)),
            "rmse": float(rmse_real), "mae": float(mae_real),
            "cg_pearson_mean": direct.get("cg_pearson_mean", np.nan),
            "cg_spearman_mean": direct.get("cg_spearman_mean", np.nan),
            "cg_dcor_mean": direct.get("cg_dcor_mean", np.nan),
            "cg_event_gain": direct.get("cg_event_gain", np.nan),
            "cg_event_hit": direct.get("cg_event_hit", np.nan),
            "cg_maxcorr": direct.get("cg_maxcorr", np.nan),
            "cg_bestlag": direct.get("cg_bestlag", np.nan),
            "gc_kernel_tod_dcor": direct.get("gc_kernel_tod_dcor", np.nan),
            "gc_feat_tod_dcor": direct.get("gc_feat_tod_dcor", np.nan),
            "gc_feat_tod_r2": direct.get("gc_feat_tod_r2", np.nan),
            "gc_kernel_feat_dcor": direct.get("gc_kernel_feat_dcor", np.nan),
            "gc_kernel_feat_align": direct.get("gc_kernel_feat_align", np.nan),
        }
        _append_or_update_results(
            results_root / f"results_{EXP_TAG}.csv",
            row,
            subset=["dataset", "horizon", "seed", "mode", "model_tag", "experiment_type"]
        )
```

#### 3.6 run 메서드

**수정:** 라인 347-386 (함수 호출 인자 수정)

```python
    def run(self):
        """
        run_suite.py에서 호출. 학습-검증-테스트, 그림/표 저장, 정리까지 일괄.
        """
        dataset = str(self.cfg.get("dataset") or getattr(self, "dataset_tag", ""))
        horizon = int(self.cfg.get("horizon", 96))
        seed = int(self.cfg.get("seed", 42))
        mode = str(self.cfg.get("mode", "none"))
        model_tag = getattr(self.model, "model_tag", "HyperConv")
        run_tag = f"{EXP_TAG}_{dataset}_{horizon}_{seed}_{mode}"
        
        try:
            # 1) 학습
            self.train()
            
            # 2) 평가
            direct = self.evaluate_test()
            hooks = self._last_hooks_data
            
            # 3) 즉시 저장
            self._after_eval_save(dataset, horizon, seed, mode, direct, hooks, model_tag, run_tag)
            
            # 4) Δ 집계/그림 사후 재구성
            results_root = RESULTS_ROOT
            fdir = results_root / f"results_{EXP_TAG}" / dataset / "forest_plot"
            hdir = results_root / f"results_{EXP_TAG}" / dataset / "gate_tod_heatmap"
            bdir = results_root / f"results_{EXP_TAG}" / dataset / "perturb_delta_bar"
            bdir.mkdir(parents=True, exist_ok=True)
            
            # 함수 시그니처에 맞춰 호출 (pair_map 제거!)
            rebuild_w3_forest_summary(
                detail_csv=fdir / "forest_plot_detail.csv",
                summary_csv=fdir / "forest_plot_summary.csv",
                gate_tod_summary_csv=hdir / "gate_tod_heatmap_summary.csv",
                group_keys=("experiment_type", "dataset", "horizon")
            )
            rebuild_w3_perturb_delta_bar(
                results_csv=results_root / f"results_{EXP_TAG}.csv",
                detail_csv=bdir / "perturb_delta_bar_detail.csv",
                summary_csv=bdir / "perturb_delta_bar_summary.csv",
            )
        finally:
            self.cleanup()
```

## 4. 검증 체크리스트

### 필수 요소 확인

- [ ] (사용자 요청) hp2_config.yaml 의 perturb_cfg: 항목이 적절하게 기재되어 실험이 동작하는지 확인
- [ ] (사용자 요청) hp2_config.yaml 의 perturb_cfg: 항목에 기재된 ETTm2와 ETTh2의 교란 강도가 적절한지 확인. 기존 실험들에서는 코드가 동작하여 results_W3.csv 에 none, tod_shift, smooth 가 mode 컬럼에 작성되었더라도 모든 성능 값이 세 mode 가 동일하여 실험에 실패한 경우가 잦았음.
- [ ] `_create_model()` 메서드 존재
- [ ] `_append_or_update_results()` 로직 구현
- [ ] `compute_and_save_w3_gate_tod_heatmap()`에 `tod_vec` 전달
- [ ] `rebuild_w3_forest_summary()` 시그니처 일치
- [ ] `rebuild_w3_perturb_delta_bar()` 시그니처 일치
- [ ] import 중복 제거
- [ ] 라인 389-781 삭제

### 구조 개선 확인

- [ ] 유틸 함수 상단 정리 (_infer_tod_bins, _default_perturb_cfg 등)
- [ ] _W3PerturbWrapper 간소화 (_apply_tod_shift, _apply_smooth)
- [ ] `@torch.no_grad()` 데코레이터 적용
- [ ] `_ctx()` 헬퍼 메서드 추가
- [ ] 중복 코드 제거

## 5. 테스트 전략

### 단계 1: 구문 검증

```bash
python -m py_compile experiments/w3_experiment.py
```

### 단계 2: Import 검증

```bash
python -c "from experiments.w3_experiment import W3Experiment; print('Import OK')"
```

### 단계 3: 인스턴스화 검증

```python
from config.config import load_hp2_config
cfg = load_hp2_config()
cfg.update({"experiment_type": "W3", "dataset": "ETTm2", "mode": "none"})
exp = W3Experiment(cfg)
print("Instance OK")
```

## 6. 주요 변경 사항 요약

### 구조 개선

1. 유틸 함수 상단 정리 (버전 2 스타일)
2. _W3PerturbWrapper 간소화 및 `@torch.no_grad()` 추가
3. `_ctx()` 헬퍼 메서드로 중복 제거
4. 상수 `RESULTS_ROOT`, `MODES` 추가

### 버그 수정

1. `_create_model()` 메서드 유지 (버전 1)
2. `_append_or_update_results` 인라인 구현 (버전 1)
3. `compute_and_save_w3_gate_tod_heatmap()`에 `tod_vec` 전달
4. `rebuild_*` 함수들 시그니처 수정 (pair_map 제거)

### 성능 최적화

1. `@torch.no_grad()` 데코레이터로 교란 메서드 최적화
2. `_detect_layout()`, `_moving_avg_1d()`로 텐서 처리 명확화

## 7. 예상 결과

### 성공 시나리오

- 세 모드(none, tod_shift, smooth) 각각 독립 실행 성공
- results_W3.csv에 모든 지표 저장
- forest_plot, gate_tod_heatmap, gate_distribution 파일 생성
- perturb_delta_bar summary/detail 생성
- .pt 파일 자동 정리

### 실패 시나리오 대응

- `tod_vec=None`인 경우 w3_plotting_metrics.py 내부에서 처리
- hooks_data가 빈 경우 빈 딕셔너리로 전달
- 지표 누락 시 np.nan으로 대체

## 8. 최종 파일 구조

```
experiments/w3_experiment.py (약 400 라인)
├── Import 및 상수 정의
├── 유틸 함수
│   ├── _infer_tod_bins()
│   ├── _default_perturb_cfg()
│   ├── _detect_layout()
│   └── _moving_avg_1d()
├── _W3PerturbWrapper 클래스
│   ├── __init__()
│   ├── forward()
│   ├── __getattr__()
│   ├── _apply_tod_shift()
│   └── _apply_smooth()
└── W3Experiment 클래스
    ├── __init__()
    ├── _create_model()
    ├── _ctx()
    ├── evaluate_test()
    ├── _after_eval_save()
    └── run()
```