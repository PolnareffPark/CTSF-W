<!-- 9a93c5ab-08ec-4754-a148-7a9d1165d777 06141d5a-373d-4d93-b885-1687bf0f6df4 -->
# W3 실험 치명적 결함 수정 플랜

## 발견된 치명적 결함

### 치명적 결함 1: compute_and_save_w3_gate_tod_heatmap 함수 시그니처 불일치 (CRITICAL)

**문제 위치**:

- `utils/experiment_plotting_metrics/w3_plotting_metrics.py`, line 197
- `experiments/w3_experiment.py`, line 710-717

**현재 상황**:

**함수 정의** (w3_plotting_metrics.py, line 197):

```python
def compute_and_save_w3_gate_tod_heatmap(ctx, metrics, out_dir, amp_method="range"):
    """
    게이트×TOD 히트맵 저장 (W3)
    ...
    """
    # 입력 추출(베이스라인 기준)
    s = np.asarray(metrics.get("gate_tod_mean_s", []), dtype=np.float64)
    m = np.asarray(metrics.get("gate_tod_mean_m", []), dtype=np.float64)
    d = np.asarray(metrics.get("gate_tod_mean_d", []), dtype=np.float64)
```

**함수 호출** (w3_experiment.py, line 710-717):

```python
compute_and_save_w3_gate_tod_heatmap(
    {**ctx, "plot_type": "gate_tod_heatmap"},
    hooks_data=hooks,  # ← 키워드 인자
    tod_vec=tod_vec,   # ← 키워드 인자
    dataset=dataset,   # ← 키워드 인자
    out_dir=heatmap_dir,
    amp_method="range",
)
```

**문제점**:

1. 함수는 2번째 위치 인자로 `metrics`를 받지만, 호출 시 키워드 인자 `hooks_data`, `tod_vec`, `dataset`을 전달합니다.
2. `metrics` 매개변수는 `gate_tod_mean_s`, `gate_tod_mean_m`, `gate_tod_mean_d` 키를 가진 딕셔너리를 예상하지만, `hooks_data`는 게이트 원본 데이터를 담고 있습니다.
3. 함수 내부에서 `tod_vec`와 `dataset`을 사용하지 않으므로 데이터 변환 로직이 누락되었습니다.

**영향**:

- 실행 시 `TypeError: compute_and_save_w3_gate_tod_heatmap() got an unexpected keyword argument 'hooks_data'` 발생
- W3 실험이 완전히 실패합니다.

**해결 방안**:

**옵션 A**: 함수 시그니처를 호출에 맞게 수정 (권장)

```python
def compute_and_save_w3_gate_tod_heatmap(
    ctx,
    hooks_data: Dict[str, Any],
    tod_vec: np.ndarray,
    dataset: str,
    out_dir: str | Path,
    amp_method: str = "range"
):
    """
    게이트×TOD 히트맵 저장 (W3)
 - hooks_data에서 게이트 데이터 추출
 - tod_vec를 사용하여 TOD 인덱스 계산
 - dataset 정보를 사용하여 TOD bins 추정
    """
    # TOD bins 추정
    T = _infer_tod_bins(dataset)
    
    # hooks_data에서 게이트 수집
    gates = _collect_gate_arrays_from_hooks(hooks_data)
    if gates is None:
        return
    
    # 스테이지별 게이트 평균 계산
    stage_gates = _stage_split_mean_per_sample(gates)
    if not stage_gates or "_is_stage_dict" not in stage_gates:
        return
    
    # TOD 인덱스 계산
    tod_idx = _tod_index_from_vec(tod_vec, T)
    
    # TOD별 게이트 평균 집계
    s_array = stage_gates.get("S", np.array([]))
    m_array = stage_gates.get("M", np.array([]))
    d_array = stage_gates.get("D", np.array([]))
    
    # TOD별로 집계
    gate_tod_mean_s = np.zeros(T)
    gate_tod_mean_m = np.zeros(T)
    gate_tod_mean_d = np.zeros(T)
    
    for t in range(T):
        mask = (tod_idx == t)
        if mask.sum() > 0:
            if s_array.size > 0:
                gate_tod_mean_s[t] = s_array[mask].mean()
            if m_array.size > 0:
                gate_tod_mean_m[t] = m_array[mask].mean()
            if d_array.size > 0:
                gate_tod_mean_d[t] = d_array[mask].mean()
    
    # 기존 로직에 맞게 metrics 딕셔너리 생성
    metrics = {
        "gate_tod_mean_s": gate_tod_mean_s,
        "gate_tod_mean_m": gate_tod_mean_m,
        "gate_tod_mean_d": gate_tod_mean_d,
    }
    
    # 기존 처리 로직 이어서...
    s = np.asarray(metrics.get("gate_tod_mean_s", []), dtype=np.float64)
    m = np.asarray(metrics.get("gate_tod_mean_m", []), dtype=np.float64)
    d = np.asarray(metrics.get("gate_tod_mean_d", []), dtype=np.float64)
    # ... 나머지 코드는 그대로 유지
```

**옵션 B**: 호출 코드를 함수 시그니처에 맞게 수정 (비권장 - 데이터 변환 로직 필요)

---

### 치명적 결함 2: _append_or_update_row, _append_or_update_rows 함수 중복 정의 (MEDIUM)

**문제 위치**: `utils/experiment_plotting_metrics/w3_plotting_metrics.py`

**중복 정의**:

- **첫 번째 정의**: Line 24-43
                                - `_append_or_update_rows`: 간단한 구현, `_atomic_write` 사용
                                - `_append_or_update_row`: `_append_or_update_rows` 호출하는 래퍼

- **두 번째 정의**: Line 138-177
                                - `_append_or_update_row`: 복잡한 구현, `_atomic_write_csv`, `_mask` 함수 사용
                                - `_append_or_update_rows`: 복잡한 구현, `_atomic_write_csv`, `_mask` 함수 사용

**문제점**:

1. Python은 마지막 정의만 유지하므로 첫 번째 정의(line 24-43)는 무시됩니다.
2. 두 구현이 다른 헬퍼 함수를 사용합니다:

                                                - 첫 번째: `_atomic_write` (line 20-22에 정의)
                                                - 두 번째: `_atomic_write_csv` (line 132-136에 정의)

3. 두 번째 정의는 `_mask` 함수에 의존 (line 179-186)
4. 코드가 혼란스럽고 의도가 불명확합니다.

**영향**:

- 현재는 두 번째 정의가 사용되므로 기능적으로는 작동할 수 있습니다.
- 유지보수성이 매우 낮고, 향후 버그의 원인이 될 수 있습니다.
- 첫 번째 정의를 참조하는 코드가 있다면 예상과 다르게 동작합니다.

**해결 방안**:

1. 첫 번째 정의(line 24-43) 삭제
2. `_atomic_write` 함수도 삭제 (line 20-22)
3. 두 번째 정의만 유지 (line 138-177)

---

### 잠재적 결함 3: _atomic_write와 _atomic_write_csv 중복

**문제 위치**: `utils/experiment_plotting_metrics/w3_plotting_metrics.py`

**중복 정의**:

- `_atomic_write`: Line 20-22
- `_atomic_write_csv`: Line 132-136

**두 함수 비교**:

```python
# Line 20-22
def _atomic_write(df: pd.DataFrame, path: Path) -> None:
    tmp = path.with_suffix(path.suffix + ".tmp")
    df.to_csv(tmp, index=False); tmp.replace(path)

# Line 132-136
def _atomic_write_csv(path: Path, df: pd.DataFrame) -> None:
    path = Path(path)
    tmp = path.with_suffix(".tmp.csv")
    df.to_csv(tmp, index=False)
    tmp.replace(path)
```

**차이점**:

1. 매개변수 순서가 다름
2. `_atomic_write_csv`는 `path`를 `Path`로 변환
3. 임시 파일 이름이 다름: `.suffix + ".tmp"` vs `".tmp.csv"`

**문제점**:

- 같은 기능을 하는 두 함수가 존재
- 혼란을 야기하고 유지보수 어려움

**해결 방안**:

1. `_atomic_write` 함수 삭제
2. `_atomic_write_csv` 함수만 사용
3. 또는 `_atomic_write_csv`를 `_atomic_write`로 이름 변경하고 통일

---

## 수정 우선순위

| 순위 | 문제 | 중요도 | 영향 | 수정 난이도 |

|------|------|--------|------|-------------|

| 1 | compute_and_save_w3_gate_tod_heatmap 시그니처 불일치 | CRITICAL | 실행 완전 실패 | 중간 |

| 2 | _append_or_update_* 함수 중복 | MEDIUM | 혼란, 잠재적 버그 | 쉬움 |

| 3 | _atomic_write* 함수 중복 | LOW | 혼란 | 쉬움 |

---

## 구현 단계

### Phase 1: compute_and_save_w3_gate_tod_heatmap 수정 (CRITICAL)

**Step 1.1**: 함수 시그니처 수정

**파일**: `utils/experiment_plotting_metrics/w3_plotting_metrics.py`, line 197

**수정 전**:

```python
def compute_and_save_w3_gate_tod_heatmap(ctx, metrics, out_dir, amp_method="range"):
```

**수정 후**:

```python
def compute_and_save_w3_gate_tod_heatmap(
    ctx: Dict[str, Any],
    hooks_data: Dict[str, Any],
    tod_vec: np.ndarray,
    dataset: str,
    out_dir: str | Path,
    amp_method: str = "range"
):
```

**Step 1.2**: 함수 내부 로직 추가 (line 209 바로 다음)

기존 line 209 이후 코드:

```python
    def _to_f32(x): 
        try: return np.float32(x).item()
        except Exception: return np.nan
    # ...
    # 입력 추출(베이스라인 기준)
    s = np.asarray(metrics.get("gate_tod_mean_s", []), dtype=np.float64)
    m = np.asarray(metrics.get("gate_tod_mean_m", []), dtype=np.float64)
    d = np.asarray(metrics.get("gate_tod_mean_d", []), dtype=np.float64)
```

**수정**: line 228 이전에 다음 코드 삽입:

```python
    # TOD bins 추정
    T = _infer_tod_bins(dataset)
    
    # hooks_data에서 게이트 수집
    gates = _collect_gate_arrays_from_hooks(hooks_data)
    if gates is None:
        # 빈 결과 저장
        out_dir = Path(out_dir)
        out_dir.mkdir(parents=True, exist_ok=True)
        _atomic_write_csv(out_dir / "gate_tod_heatmap_summary.csv", 
                          pd.DataFrame([{**ctx, "tod_bins": 0, "tod_amp_mean": np.nan}]))
        return
    
    # 스테이지별 게이트 평균 계산
    stage_gates = _stage_split_mean_per_sample(gates)
    if not stage_gates:
        out_dir = Path(out_dir)
        out_dir.mkdir(parents=True, exist_ok=True)
        _atomic_write_csv(out_dir / "gate_tod_heatmap_summary.csv", 
                          pd.DataFrame([{**ctx, "tod_bins": 0, "tod_amp_mean": np.nan}]))
        return
    
    # TOD 인덱스 계산
    if not isinstance(tod_vec, np.ndarray) or tod_vec.size == 0:
        out_dir = Path(out_dir)
        out_dir.mkdir(parents=True, exist_ok=True)
        _atomic_write_csv(out_dir / "gate_tod_heatmap_summary.csv", 
                          pd.DataFrame([{**ctx, "tod_bins": 0, "tod_amp_mean": np.nan}]))
        return
    
    tod_idx = _tod_index_from_vec(tod_vec, T)
    
    # TOD별 게이트 평균 집계
    s_array = stage_gates.get("S", np.array([]))
    m_array = stage_gates.get("M", np.array([]))
    d_array = stage_gates.get("D", np.array([]))
    
    # TOD별로 집계
    gate_tod_mean_s = np.full(T, np.nan, dtype=np.float64)
    gate_tod_mean_m = np.full(T, np.nan, dtype=np.float64)
    gate_tod_mean_d = np.full(T, np.nan, dtype=np.float64)
    
    for t in range(T):
        mask = (tod_idx == t)
        if mask.sum() > 0:
            if s_array.size > 0 and mask.sum() <= s_array.size:
                gate_tod_mean_s[t] = s_array[mask].mean()
            if m_array.size > 0 and mask.sum() <= m_array.size:
                gate_tod_mean_m[t] = m_array[mask].mean()
            if d_array.size > 0 and mask.sum() <= d_array.size:
                gate_tod_mean_d[t] = d_array[mask].mean()
    
    # metrics 딕셔너리 생성
    metrics = {
        "gate_tod_mean_s": gate_tod_mean_s,
        "gate_tod_mean_m": gate_tod_mean_m,
        "gate_tod_mean_d": gate_tod_mean_d,
    }
```

**Step 1.3**: 기존 line 228-232 유지 (이제 metrics가 정의되었으므로 정상 작동)

---

### Phase 2: 중복 함수 제거 (MEDIUM)

**Step 2.1**: 첫 번째 _append_or_update_* 정의 삭제

**파일**: `utils/experiment_plotting_metrics/w3_plotting_metrics.py`, line 20-43

**삭제할 코드**:

```python
def _atomic_write(df: pd.DataFrame, path: Path) -> None:
    tmp = path.with_suffix(path.suffix + ".tmp")
    df.to_csv(tmp, index=False); tmp.replace(path)

def _append_or_update_rows(csv_path: str | Path, rows: List[Dict[str,Any]], subset_keys: List[str]) -> None:
    if not rows: return
    path = _ensure_dir(csv_path)
    new = pd.DataFrame(rows)
    if path.exists():
        old = pd.read_csv(path)
        # union
        for c in new.columns:
            if c not in old.columns: old[c] = np.nan
        for c in old.columns:
            if c not in new.columns: new[c] = np.nan
        df = pd.concat([old, new], ignore_index=True)
        df.drop_duplicates(subset=subset_keys, keep="last", inplace=True)
        _atomic_write(df, path)
    else:
        new.drop_duplicates(subset=subset_keys, keep="last", inplace=True)
        _atomic_write(new, path)

def _append_or_update_row(csv_path: str | Path, row: Dict[str,Any], subset_keys: List[str]) -> None:
    _append_or_update_rows(csv_path, [row], subset_keys)
```

**Step 2.2**: Line 번호 조정 확인

- 삭제 후 나머지 코드의 line 번호가 변경되므로 주의

---

### Phase 3: 검증 (REQUIRED)

**Step 3.1**: 구문 검사

```bash
python -m py_compile utils/experiment_plotting_metrics/w3_plotting_metrics.py
python -m py_compile experiments/w3_experiment.py
```

**Step 3.2**: Import 검사

```bash
python -c "from utils.experiment_plotting_metrics.w3_plotting_metrics import compute_and_save_w3_gate_tod_heatmap; print('OK')"
```

**Step 3.3**: 함수 시그니처 검증 스크립트

```python
import inspect
from utils.experiment_plotting_metrics.w3_plotting_metrics import compute_and_save_w3_gate_tod_heatmap

sig = inspect.signature(compute_and_save_w3_gate_tod_heatmap)
params = list(sig.parameters.keys())
print(f"Parameters: {params}")

# 예상: ['ctx', 'hooks_data', 'tod_vec', 'dataset', 'out_dir', 'amp_method']
expected = ['ctx', 'hooks_data', 'tod_vec', 'dataset', 'out_dir', 'amp_method']
assert params == expected, f"Mismatch: {params} != {expected}"
print("✓ Signature verification passed")
```

**Step 3.4**: 실제 실험 스모크 테스트

```bash
# ETTm2, none 모드로 간단 실행
python main.py --experiment W3 --dataset ETTm2 --horizon 96 --seed 42 --mode none
```

---

## 예상 결과

### 수정 전

- W3 실험 실행 시 `TypeError: compute_and_save_w3_gate_tod_heatmap() got an unexpected keyword argument 'hooks_data'` 발생
- 실험 완전 실패

### 수정 후

- W3 실험이 정상적으로 실행
- gate_tod_heatmap CSV 파일들이 올바르게 생성
- TOD별 게이트 평균이 정확하게 계산됨

---

## 예상 소요 시간

- Phase 1 (함수 시그니처 수정): 30분
- Phase 2 (중복 함수 제거): 10분
- Phase 3 (검증): 15분
- **총: 55분**

---

## 주의사항

1. **Phase 1은 필수**입니다. 이것이 없으면 W3 실험이 전혀 실행되지 않습니다.

2. **Phase 2는 권장**입니다. 코드 품질 향상을 위해 중요하지만, 기능적으로는 현재도 작동합니다.

3. **데이터 변환 로직**이 복잡하므로 Phase 1의 코드를 주의 깊게 작성해야 합니다.

4. **TOD 인덱스 계산**이 올바른지 확인해야 합니다. `tod_vec`의 형식과 `_tod_index_from_vec` 함수의 동작을 이해해야 합니다.

5. **Stage 게이트 집계**가 올바른지 확인해야 합니다. `_stage_split_mean_per_sample`와 `_collect_gate_arrays_from_hooks` 함수의 동작을 이해해야 합니다.